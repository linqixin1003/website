#!/usr/bin/env python3
"""
å¾·è¯­ç¿»è¯‘è´¨é‡å…¨é¢æ£€æŸ¥è„šæœ¬
éªŒè¯æ‰€æœ‰ä¿®å¤æ˜¯å¦å®Œæˆ
"""
import os
import re
from bs4 import BeautifulSoup

def check_german_errors(content, filename):
    """æ£€æŸ¥å¾·è¯­ç¿»è¯‘é”™è¯¯"""
    errors = []
    
    # 1. æ£€æŸ¥å¸¸è§çš„å¾·è¯­è¯­æ³•é”™è¯¯
    grammar_errors = [
        (r'\bsterben\b', "é”™è¯¯ä½¿ç”¨'sterben'ä½œä¸ºå®šå† è¯"),
        (r'\bder/sterben/das\b', "é”™è¯¯çš„å¾·è¯­å®šå† è¯æ ¼å¼"),
        (r'\bjener/jene/jenes\b', "åº”è¯¥ä½¿ç”¨'diese'è€Œä¸æ˜¯'jener/jene/jenes'"),
    ]
    
    for pattern, description in grammar_errors:
        matches = re.findall(pattern, content, re.IGNORECASE)
        if matches:
            errors.append(f"è¯­æ³•é”™è¯¯: {description} - æ‰¾åˆ°{len(matches)}å¤„")
    
    # 2. æ£€æŸ¥HTMLæ ‡ç­¾é”™è¯¯
    html_errors = [
        (r'<stark>', "é”™è¯¯çš„HTMLæ ‡ç­¾'stark'ï¼Œåº”è¯¥æ˜¯'strong'"),
        (r'</stark>', "é”™è¯¯çš„HTMLç»“æŸæ ‡ç­¾'stark'"),
    ]
    
    for pattern, description in html_errors:
        matches = re.findall(pattern, content, re.IGNORECASE)
        if matches:
            errors.append(f"HTMLé”™è¯¯: {description} - æ‰¾åˆ°{len(matches)}å¤„")
    
    # 3. æ£€æŸ¥CSSç±»åé”™è¯¯
    css_errors = [
        (r'equipment-Beschreibung', "é”™è¯¯çš„CSSç±»åï¼Œåº”è¯¥æ˜¯'equipment-description'"),
        (r'haupt-text', "é”™è¯¯çš„CSSç±»åï¼Œåº”è¯¥æ˜¯'main-text'"),
    ]
    
    for pattern, description in css_errors:
        matches = re.findall(pattern, content, re.IGNORECASE)
        if matches:
            errors.append(f"CSSé”™è¯¯: {description} - æ‰¾åˆ°{len(matches)}å¤„")
    
    # 4. æ£€æŸ¥ä¸­æ–‡å†…å®¹æ®‹ç•™
    chinese_patterns = [
        (r'[è§‚é¸ŸæŒ‡å—]', "ä¸­æ–‡ï¼šè§‚é¸ŸæŒ‡å—"),
        (r'[çŸ¥è¯†åº“]', "ä¸­æ–‡ï¼šçŸ¥è¯†åº“"),
        (r'[ç§‘å­¦å¥‡è§‚]', "ä¸­æ–‡ï¼šç§‘å­¦å¥‡è§‚"),
        (r'[ç”Ÿæ€å­¦]', "ä¸­æ–‡ï¼šç”Ÿæ€å­¦"),
        (r'[å® ç‰©æŠ¤ç†]', "ä¸­æ–‡ï¼šå® ç‰©æŠ¤ç†"),
        (r'[\u4e00-\u9fff]+', "å…¶ä»–ä¸­æ–‡å­—ç¬¦"),
    ]
    
    for pattern, description in chinese_patterns:
        matches = re.findall(pattern, content)
        if matches:
            errors.append(f"ä¸­æ–‡æ®‹ç•™: {description} - æ‰¾åˆ°{len(matches)}å¤„: {matches[:3]}")
    
    # 5. æ£€æŸ¥è‹±å¾·æ··åˆé”™è¯¯
    mixed_errors = [
        (r'\bist\s+usually\b', "è‹±å¾·æ··åˆï¼š'ist usually'"),
        (r'\bist\s+minimal\b', "è‹±å¾·æ··åˆï¼š'ist minimal'"),
        (r'\bwhen\s+Sie\b', "è‹±å¾·æ··åˆï¼š'when Sie'"),
        (r'\bas\s+these\s+sind\b', "è‹±å¾·æ··åˆï¼š'as these sind'"),
        (r'\bas\s+they\s+sind\b', "è‹±å¾·æ··åˆï¼š'as they sind'"),
        (r'\bmore\s+wichtig\s+than\b', "è‹±å¾·æ··åˆï¼š'more wichtig than'"),
        (r'\bif\s+Sie\b', "è‹±å¾·æ··åˆï¼š'if Sie'"),
        (r'\bto\s+improve\b', "è‹±å¾·æ··åˆï¼š'to improve'"),
        (r'\bpeak\s+activity\s+times\b', "è‹±å¾·æ··åˆï¼š'peak activity times'"),
        (r'\bin\s+most\s+Gebiete\b', "è‹±å¾·æ··åˆï¼š'in most Gebiete'"),
        (r'\bfor\s+discovery\s+und\s+wonder\b', "è‹±å¾·æ··åˆï¼š'for discovery und wonder'"),
    ]
    
    for pattern, description in mixed_errors:
        matches = re.findall(pattern, content, re.IGNORECASE)
        if matches:
            errors.append(f"è‹±å¾·æ··åˆ: {description} - æ‰¾åˆ°{len(matches)}å¤„")
    
    return errors

def check_content_quality(content, filename):
    """æ£€æŸ¥å†…å®¹è´¨é‡"""
    quality_issues = []
    
    try:
        soup = BeautifulSoup(content, 'html.parser')
        
        # æ£€æŸ¥æ ‡é¢˜è¯­è¨€
        title = soup.find('title')
        if title and title.text:
            if re.search(r'[\u4e00-\u9fff]', title.text):
                quality_issues.append("æ ‡é¢˜åŒ…å«ä¸­æ–‡å­—ç¬¦")
        
        # æ£€æŸ¥metaä¿¡æ¯
        lang_attr = soup.find('html', {'lang': True})
        if lang_attr and lang_attr.get('lang') != 'de':
            quality_issues.append(f"HTML langå±æ€§ä¸æ­£ç¡®: {lang_attr.get('lang')}")
        
        # æ£€æŸ¥ä¸»è¦å†…å®¹æ˜¯å¦ä¸ºå¾·è¯­
        main_content = soup.get_text()
        chinese_count = len(re.findall(r'[\u4e00-\u9fff]', main_content))
        if chinese_count > 5:  # å…è®¸å°‘é‡ä¸­æ–‡å­—ç¬¦ï¼ˆå¯èƒ½åœ¨æ³¨é‡Šä¸­ï¼‰
            quality_issues.append(f"å†…å®¹åŒ…å«è¿‡å¤šä¸­æ–‡å­—ç¬¦: {chinese_count}ä¸ª")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰åˆç†çš„å¾·è¯­å†…å®¹
        german_indicators = ['der', 'die', 'das', 'und', 'oder', 'fÃ¼r', 'von', 'zu', 'mit']
        german_count = sum(len(re.findall(r'\b' + word + r'\b', main_content, re.IGNORECASE)) for word in german_indicators)
        
        if german_count < 10:
            quality_issues.append("å¾·è¯­ç‰¹å¾è¯æ±‡è¿‡å°‘ï¼Œå¯èƒ½ä¸æ˜¯å¾·è¯­å†…å®¹")
            
    except Exception as e:
        quality_issues.append(f"è§£æHTMLæ—¶å‡ºé”™: {e}")
    
    return quality_issues

def analyze_file(file_path):
    """åˆ†æå•ä¸ªæ–‡ä»¶"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # æ£€æŸ¥ç¿»è¯‘é”™è¯¯
        translation_errors = check_german_errors(content, file_path)
        
        # æ£€æŸ¥å†…å®¹è´¨é‡
        quality_issues = check_content_quality(content, file_path)
        
        return {
            'file': file_path,
            'translation_errors': translation_errors,
            'quality_issues': quality_issues,
            'total_issues': len(translation_errors) + len(quality_issues)
        }
        
    except Exception as e:
        return {
            'file': file_path,
            'translation_errors': [f"æ–‡ä»¶è¯»å–é”™è¯¯: {e}"],
            'quality_issues': [],
            'total_issues': 1
        }

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ” å¼€å§‹å¾·è¯­ç¿»è¯‘è´¨é‡å…¨é¢æ£€æŸ¥...")
    print("=" * 60)
    
    # å¾·è¯­æ–‡ä»¶ç›®å½•
    german_dirs = [
        'de/birdwatching',
        'de/knowledge', 
        'de/ecology',
        'de/pet-care',
        'de/scientific-wonders'
    ]
    
    all_results = []
    total_files = 0
    problematic_files = 0
    
    for dir_path in german_dirs:
        if os.path.exists(dir_path):
            print(f"\nğŸ“ æ£€æŸ¥ç›®å½•: {dir_path}")
            
            for filename in os.listdir(dir_path):
                if filename.endswith('.html') and not '.backup' in filename:
                    file_path = os.path.join(dir_path, filename)
                    total_files += 1
                    
                    result = analyze_file(file_path)
                    all_results.append(result)
                    
                    if result['total_issues'] > 0:
                        problematic_files += 1
                        print(f"âŒ {filename}: {result['total_issues']} ä¸ªé—®é¢˜")
                        
                        for error in result['translation_errors']:
                            print(f"   ğŸ”¸ ç¿»è¯‘é”™è¯¯: {error}")
                        
                        for issue in result['quality_issues']:
                            print(f"   ğŸ”¸ è´¨é‡é—®é¢˜: {issue}")
                    else:
                        print(f"âœ… {filename}: æ— é—®é¢˜")
    
    # ç”Ÿæˆæ€»ç»“æŠ¥å‘Š
    print("\n" + "=" * 60)
    print("ğŸ“Š æ£€æŸ¥æ€»ç»“æŠ¥å‘Š")
    print("=" * 60)
    print(f"ğŸ“ æ£€æŸ¥ç›®å½•æ•°: {len(german_dirs)}")
    print(f"ğŸ“„ æ£€æŸ¥æ–‡ä»¶æ•°: {total_files}")
    print(f"âŒ æœ‰é—®é¢˜æ–‡ä»¶: {problematic_files}")
    print(f"âœ… æ— é—®é¢˜æ–‡ä»¶: {total_files - problematic_files}")
    print(f"ğŸ¯ è´¨é‡è¯„åˆ†: {((total_files - problematic_files) / total_files * 100):.1f}%")
    
    # ç»Ÿè®¡å„ç±»é—®é¢˜
    translation_error_count = sum(len(r['translation_errors']) for r in all_results)
    quality_issue_count = sum(len(r['quality_issues']) for r in all_results)
    
    print(f"\nğŸ”¸ ç¿»è¯‘é”™è¯¯æ€»æ•°: {translation_error_count}")
    print(f"ğŸ”¸ è´¨é‡é—®é¢˜æ€»æ•°: {quality_issue_count}")
    print(f"ğŸ”¸ æ€»é—®é¢˜æ•°: {translation_error_count + quality_issue_count}")
    
    if problematic_files == 0:
        print("\nğŸ‰ æ­å–œï¼æ‰€æœ‰å¾·è¯­æ–‡ä»¶éƒ½å·²é€šè¿‡è´¨é‡æ£€æŸ¥ï¼")
        print("âœ¨ å¾·è¯­ç¿»è¯‘è´¨é‡è¾¾åˆ°å‘å¸ƒæ ‡å‡†")
    else:
        print(f"\nâš ï¸  è¿˜æœ‰ {problematic_files} ä¸ªæ–‡ä»¶éœ€è¦è¿›ä¸€æ­¥ä¿®å¤")
        
        # æ˜¾ç¤ºæœ€éœ€è¦å…³æ³¨çš„æ–‡ä»¶
        problematic_results = [r for r in all_results if r['total_issues'] > 0]
        problematic_results.sort(key=lambda x: x['total_issues'], reverse=True)
        
        print("\nğŸ”§ æœ€éœ€è¦å…³æ³¨çš„æ–‡ä»¶:")
        for i, result in enumerate(problematic_results[:5]):
            print(f"{i+1}. {result['file']}: {result['total_issues']} ä¸ªé—®é¢˜")

if __name__ == "__main__":
    main() 