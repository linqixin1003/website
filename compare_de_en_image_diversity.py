#!/usr/bin/env python3
"""
æ¯”è¾ƒå¾·è¯­å’Œè‹±è¯­ç‰ˆæœ¬çš„å¤´éƒ¨å›¾ç‰‡å¤šæ ·æ€§
"""

import os
import re
from collections import Counter, defaultdict

def extract_header_image(file_path):
    """æå–æ–‡ä»¶çš„å¤´éƒ¨å›¾ç‰‡è·¯å¾„"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # æŸ¥æ‰¾CSSèƒŒæ™¯å›¾ç‰‡
        css_match = re.search(r"url\('(../../images/[^']+)'\)", content)
        if css_match:
            return css_match.group(1)
        
        # æŸ¥æ‰¾HTML imgæ ‡ç­¾
        img_match = re.search(r'<img[^>]+src="(../../images/[^"]+)"[^>]*>', content)
        if img_match:
            return img_match.group(1)
        
        return None
        
    except Exception as e:
        return None

def find_all_html_files(directory):
    """æŸ¥æ‰¾ç›®å½•ä¸‹æ‰€æœ‰HTMLæ–‡ä»¶"""
    html_files = []
    for root, dirs, files in os.walk(directory):
        for file in files:
            if file.endswith('.html') and not file.endswith('knowledge.html') and not file.endswith('index.html'):
                html_files.append(os.path.join(root, file))
    return html_files

def analyze_language_images(lang_code):
    """åˆ†æç‰¹å®šè¯­è¨€çš„å›¾ç‰‡ä½¿ç”¨æƒ…å†µ"""
    files = find_all_html_files(lang_code)
    image_usage = Counter()
    file_to_image = {}
    
    for file_path in files:
        image = extract_header_image(file_path)
        if image:
            image_usage[image] += 1
            file_to_image[file_path] = image
    
    return files, image_usage, file_to_image

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ” æ¯”è¾ƒå¾·è¯­å’Œè‹±è¯­ç‰ˆæœ¬çš„å¤´éƒ¨å›¾ç‰‡å¤šæ ·æ€§...")
    
    # åˆ†æå¾·è¯­ç‰ˆæœ¬
    print("\nğŸ“‹ åˆ†æå¾·è¯­ç‰ˆæœ¬...")
    de_files, de_image_usage, de_file_to_image = analyze_language_images('de')
    
    # åˆ†æè‹±è¯­ç‰ˆæœ¬
    print("ğŸ“‹ åˆ†æè‹±è¯­ç‰ˆæœ¬...")
    en_files, en_image_usage, en_file_to_image = analyze_language_images('en')
    
    print("\n" + "=" * 80)
    print("ğŸ“Š å¾·è¯­ vs è‹±è¯­ å›¾ç‰‡ä½¿ç”¨å¯¹æ¯”")
    print("=" * 80)
    
    # åŸºæœ¬ç»Ÿè®¡
    print(f"{'æŒ‡æ ‡':<30} {'å¾·è¯­':<15} {'è‹±è¯­':<15}")
    print("-" * 60)
    print(f"{'æ€»æ–‡ä»¶æ•°':<30} {len(de_files):<15} {len(en_files):<15}")
    print(f"{'æœ‰å¤´éƒ¨å›¾ç‰‡çš„æ–‡ä»¶':<30} {len(de_file_to_image):<15} {len(en_file_to_image):<15}")
    print(f"{'ä½¿ç”¨çš„ä¸åŒå›¾ç‰‡æ•°':<30} {len(de_image_usage):<15} {len(en_image_usage):<15}")
    
    # é‡å¤ä½¿ç”¨åˆ†æ
    de_duplicates = sum(1 for count in de_image_usage.values() if count > 1)
    en_duplicates = sum(1 for count in en_image_usage.values() if count > 1)
    
    de_unique = len(de_image_usage) - de_duplicates
    en_unique = len(en_image_usage) - en_duplicates
    
    print(f"{'é‡å¤ä½¿ç”¨çš„å›¾ç‰‡æ•°':<30} {de_duplicates:<15} {en_duplicates:<15}")
    print(f"{'å”¯ä¸€ä½¿ç”¨çš„å›¾ç‰‡æ•°':<30} {de_unique:<15} {en_unique:<15}")
    
    if len(de_image_usage) > 0:
        de_unique_rate = (de_unique / len(de_image_usage)) * 100
    else:
        de_unique_rate = 0
        
    if len(en_image_usage) > 0:
        en_unique_rate = (en_unique / len(en_image_usage)) * 100
    else:
        en_unique_rate = 0
    
    print(f"{'å›¾ç‰‡å”¯ä¸€æ€§æ¯”ä¾‹':<30} {de_unique_rate:.1f}%{'':<10} {en_unique_rate:.1f}%")
    
    # æ£€æŸ¥å¾·è¯­å’Œè‹±è¯­æ˜¯å¦ä½¿ç”¨ç›¸åŒçš„å›¾ç‰‡
    print(f"\nğŸ” å¾·è¯­å’Œè‹±è¯­å›¾ç‰‡ä½¿ç”¨å¯¹æ¯”:")
    
    # æ‰¾åˆ°å¯¹åº”çš„æ–‡ä»¶å¯¹
    matched_pairs = []
    for de_file in de_file_to_image.keys():
        en_file = de_file.replace('de/', 'en/')
        if en_file in en_file_to_image:
            de_image = de_file_to_image[de_file]
            en_image = en_file_to_image[en_file]
            matched_pairs.append((de_file, en_file, de_image, en_image))
    
    print(f"   æ‰¾åˆ° {len(matched_pairs)} å¯¹å¯¹åº”çš„å¾·è¯­-è‹±è¯­æ–‡ä»¶")
    
    # æ£€æŸ¥å›¾ç‰‡æ˜¯å¦åŒ¹é…
    matching_images = 0
    different_images = 0
    
    print(f"\nğŸ“‹ å›¾ç‰‡åŒ¹é…æƒ…å†µ:")
    for de_file, en_file, de_image, en_image in matched_pairs:
        if de_image == en_image:
            matching_images += 1
        else:
            different_images += 1
            de_img_name = os.path.basename(de_image)
            en_img_name = os.path.basename(en_image)
            print(f"âŒ {os.path.basename(de_file)}")
            print(f"   å¾·è¯­: {de_img_name}")
            print(f"   è‹±è¯­: {en_img_name}")
    
    print(f"\nğŸ“ˆ åŒ¹é…ç»Ÿè®¡:")
    print(f"   å›¾ç‰‡å®Œå…¨åŒ¹é…: {matching_images} å¯¹")
    print(f"   å›¾ç‰‡ä¸åŒ¹é…: {different_images} å¯¹")
    
    if len(matched_pairs) > 0:
        match_rate = (matching_images / len(matched_pairs)) * 100
        print(f"   åŒ¹é…ç‡: {match_rate:.1f}%")
    
    # æœ€é‡å¤ä½¿ç”¨çš„å›¾ç‰‡
    print(f"\nğŸ”„ æœ€å¸¸è¢«é‡å¤ä½¿ç”¨çš„å›¾ç‰‡:")
    print("å¾·è¯­ç‰ˆæœ¬:")
    de_sorted = sorted(de_image_usage.items(), key=lambda x: x[1], reverse=True)[:5]
    for image, count in de_sorted:
        if count > 1:
            print(f"   {os.path.basename(image)}: {count} æ¬¡")
    
    print("è‹±è¯­ç‰ˆæœ¬:")
    en_sorted = sorted(en_image_usage.items(), key=lambda x: x[1], reverse=True)[:5]
    for image, count in en_sorted:
        if count > 1:
            print(f"   {os.path.basename(image)}: {count} æ¬¡")
    
    # æ€»ç»“å’Œå»ºè®®
    print(f"\nğŸ’¡ åˆ†æç»“è®º:")
    if different_images > 0:
        print(f"   âŒ å‘ç° {different_images} ä¸ªæ–‡ä»¶çš„å¾·è¯­å’Œè‹±è¯­ç‰ˆæœ¬ä½¿ç”¨äº†ä¸åŒçš„å¤´éƒ¨å›¾ç‰‡")
        print(f"   ğŸ“ å»ºè®®: éœ€è¦åŒæ­¥å¾·è¯­å’Œè‹±è¯­ç‰ˆæœ¬çš„å¤´éƒ¨å›¾ç‰‡")
    else:
        print(f"   âœ… æ‰€æœ‰å¾·è¯­å’Œè‹±è¯­æ–‡ä»¶çš„å¤´éƒ¨å›¾ç‰‡éƒ½å®Œå…¨åŒ¹é…")
    
    if de_duplicates > 10 or en_duplicates > 10:
        print(f"   âš ï¸  å›¾ç‰‡é‡å¤ä½¿ç”¨è¾ƒå¤šï¼Œå¯èƒ½éœ€è¦å¢åŠ å›¾ç‰‡å¤šæ ·æ€§")
    else:
        print(f"   âœ… å›¾ç‰‡é‡å¤ä½¿ç”¨æƒ…å†µåœ¨åˆç†èŒƒå›´å†…")

if __name__ == "__main__":
    main()